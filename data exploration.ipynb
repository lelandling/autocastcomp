{"cells":[{"cell_type":"markdown","metadata":{"id":"CdqDoL8TtkNj"},"source":["# CS542 Project Submission\n","Team: Lehland Ling, Evan Powell"]},{"cell_type":"markdown","metadata":{"id":"TGyXl-5ToVzY"},"source":["# Dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32690,"status":"ok","timestamp":1683055560362,"user":{"displayName":"Evan Powell","userId":"11390524329421785152"},"user_tz":240},"id":"FTqlVgP7ncde","outputId":"6790a111-95ac-46e7-95ee-c8682e4d76ce"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in c:\\programdata\\anaconda3\\lib\\site-packages (4.28.1)"]},{"name":"stderr","output_type":"stream","text":["ERROR: huggingface-hub 0.14.1 has requirement packaging>=20.9, but you'll have packaging 20.4 which is incompatible.\n"]},{"name":"stdout","output_type":"stream","text":["\n","Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n","Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (1.18.5)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (5.3.1)\n","Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2020.6.8)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.13.3)\n","Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (20.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.14.1)\n","Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (4.47.0)\n","Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.24.0)\n","Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n","Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (0.7.4)\n","Collecting typing-extensions>=3.7.4.3\n","  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (1.25.9)\n","Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2020.6.20)\n","Installing collected packages: typing-extensions\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing-extensions 3.7.4.2\n","    Uninstalling typing-extensions-3.7.4.2:\n"]},{"name":"stderr","output_type":"stream","text":["ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Access is denied: 'c:\\\\programdata\\\\anaconda3\\\\lib\\\\site-packages\\\\__pycache__\\\\typing_extensions.cpython-38.pyc'\n","Consider using the `--user` option or check the permissions.\n","\n","ERROR: huggingface-hub 0.14.1 has requirement packaging>=20.9, but you'll have packaging 20.4 which is incompatible.\n","ERROR: huggingface-hub 0.14.1 has requirement typing-extensions>=3.7.4.3, but you'll have typing-extensions 3.7.4.2 which is incompatible.\n"]},{"name":"stdout","output_type":"stream","text":["Collecting transformers\n","  Using cached transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","Collecting torch\n","  Downloading torch-2.0.0-cp38-cp38-win_amd64.whl (172.3 MB)\n","Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (1.18.5)\n","Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.24.0)\n","Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (20.4)\n","Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2020.6.8)\n","Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n","Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (5.3.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.13.3)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Using cached huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (4.47.0)\n","Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (1.6.1)\n","Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2.11.2)\n","Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.7.4.2)\n","Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (1.25.9)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (2.4.7)\n","Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (0.7.4)\n","Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch) (1.1.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (1.1.1)\n","Requirement already satisfied: decorator>=4.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from networkx->torch) (4.4.2)\n","Installing collected packages: huggingface-hub, transformers, torch\n","Successfully installed huggingface-hub-0.14.1 torch-2.0.0 transformers-4.28.1\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ua-7nbOU1Ohu","outputId":"d41e3319-30b5-4859-dc32-3bc6b3e2794f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in links: https://download.pytorch.org/whl/cpu/torch_stable.html\n","Collecting torch\n","  Using cached https://download.pytorch.org/whl/cpu/torch-2.0.0%2Bcpu-cp38-cp38-win_amd64.whl (174.0 MB)\n","Requirement already satisfied (use --upgrade to upgrade): torch from https://download.pytorch.org/whl/cpu/torch-2.0.0%2Bcpu-cp38-cp38-win_amd64.whl in c:\\programdata\\anaconda3\\lib\\site-packages\n","Requirement already satisfied: torchvision in c:\\programdata\\anaconda3\\lib\\site-packages (0.15.1+cpu)\n","Requirement already satisfied: torchtext in c:\\programdata\\anaconda3\\lib\\site-packages (0.15.1)\n","Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2.11.2)\n","Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.0.12)\n","Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2.4)\n","Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (1.6.1)\n","Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.7.4.2)\n","Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (1.18.5)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (7.2.0)\n","Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (2.24.0)\n","Requirement already satisfied: torchdata==0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchtext) (0.6.0)\n","Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from torchtext) (4.47.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (1.1.1)\n","Requirement already satisfied: decorator>=4.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from networkx->torch) (4.4.2)\n","Requirement already satisfied: mpmath>=0.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->torch) (1.1.0)\n","Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision) (1.25.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->torchvision) (2020.6.20)\n"]}],"source":["!pip install torch torchvision torchtext -f https://download.pytorch.org/whl/cpu/torch_stable.html"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":158,"status":"ok","timestamp":1683056015266,"user":{"displayName":"Evan Powell","userId":"11390524329421785152"},"user_tz":240},"id":"9GDuXlsPnUcU","outputId":"12ac6f8c-a7ac-4815-dacc-9468714a5183"},"outputs":[{"ename":"ImportError","evalue":"cannot import name 'TypeAlias' from 'typing_extensions' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\typing_extensions.py)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[1;32m<ipython-input-1-48deadedf2ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtypes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSimpleNamespace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAutoModelForMultipleChoice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m   1120\u001b[0m \u001b[1;31m# If you edit these imports, please update torch/__init__.py.in as well\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_rng_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_rng_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmanual_seed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_seed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mserialization\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_tensor_str\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_printoptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_get_dtype_from_pickle_storage_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBinaryIO\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIO\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTypeAlias\u001b[0m  \u001b[1;31m# Python 3.10+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcopyreg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mImportError\u001b[0m: cannot import name 'TypeAlias' from 'typing_extensions' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\typing_extensions.py)"]}],"source":["import os\n","import json\n","import pickle\n","import numpy as np\n","\n","import pandas as pd\n","import torch\n","from types import SimpleNamespace\n","from transformers import AutoModel, AutoTokenizer, AutoModelForMultipleChoice, AutoModelForSequenceClassification\n","from transformers import DistilBertTokenizerFast, DistilBertForMultipleChoice, DistilBertForSequenceClassification\n","import torch.nn.functional as F\n","from scipy.special import softmax\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":42388,"status":"ok","timestamp":1683055614459,"user":{"displayName":"Evan Powell","userId":"11390524329421785152"},"user_tz":240},"id":"u0Nf1McOQryT","outputId":"c6c72f95-b927-4431-bbf7-23d6fd4be8c3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["drive.mount(\"/content/drive\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3fr4GYLunUcZ"},"outputs":[],"source":["autocast_questions = json.load(open('/content/drive/MyDrive/CS542/autocast_questions.json', encoding=\"utf-8\")) # from the Autocast dataset\n","test_questions = json.load(open('/content/drive/MyDrive/CS542/autocast_competition_test_set.json', encoding=\"utf-8\"))\n","test_ids = [q['id'] for q in test_questions]"]},{"cell_type":"markdown","metadata":{"id":"9gWl5RqtnUcb"},"source":["# Load Models Finetuned on the Training Set"]},{"cell_type":"markdown","metadata":{"id":"Z8z8tvnRqLe4"},"source":["## Random Baseline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gx25Tp3-nUce"},"outputs":[],"source":["def random_baseline_model(question):\n","    if question['qtype'] == 't/f':\n","        return np.random.random(size=2)\n","    elif question['qtype'] == 'mc':\n","        probs = np.random.random(size=len(question['choices']))\n","        return probs / probs.sum()\n","    elif question['qtype'] == 'num':\n","        return np.random.random()\n","\n","\n","def calibrated_random_baseline_model(question):\n","    if question['qtype'] == 't/f':\n","        pred_idx = np.argmax(np.random.random(size=2))\n","        pred = np.ones(2)\n","        pred[pred_idx] += 1e-5\n","        return pred / pred.sum()\n","    elif question['qtype'] == 'mc':\n","        pred_idx = np.argmax(np.random.random(size=len(question['choices'])))\n","        pred = np.ones(len(question['choices']))\n","        pred[pred_idx] += 1e-5\n","        return pred / pred.sum()\n","    elif question['qtype'] == 'num':\n","        return 0.5"]},{"cell_type":"markdown","metadata":{"id":"lPVSvVJWon3m"},"source":["## Multiple Choice Forecaster\n","to use the multiple choice forecaster, run all of the cells in this block and call `mc_predict(test_questions)` on the entire test set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iNp-P77_onex"},"outputs":[],"source":["def mc_preptest(mc_test):\n","    \"\"\"takes as input a dataframe containing the multiple choice questions and does the first step toward preprocessing\"\"\"\n","\n","    mc_test['len background'] = mc_test['background'].str.len()\n","    mc_test['len question'] = mc_test['question'].str.len()\n","    mc_test['len answers'] = mc_test['choices'].apply(lambda x : [len(ans) for ans in x])\n","    mc_test['len answers'] = mc_test['len answers'].apply(lambda x: max(x))\n","    x = len(\" [sep] \")\n","    mc_test['temp'] = mc_test['len background'] - x*2 - mc_test['len answers'] - mc_test['len question']\n","    mc_test['max context length'] = ((-1 * (mc_test['len answers'] + mc_test['len question']) + x*2) + 512)\n","\n","    test = mc_test['temp'].compare(mc_test['max context length'])\n","    mc_test['max context length'] = test.apply(lambda row: row.min(), axis=1)\n","    mc_test['prompt'] = mc_test.apply(lambda x: x['background'][:x['max context length']], axis=1)\n","    mc_test['len prompt'] = mc_test['prompt'].str.len()\n","    mc_test['len prompt'].max()\n","\n","    #return data\n","    return mc_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6tl_D2VrpbA0"},"outputs":[],"source":["def mc_preprocess_candidates(row):\n","  \"\"\"preprocesses a row of the multiple choice questions to be tokenized\"\"\"\n","  choices = []\n","  prompt =  \" [SEP] \".join([row['prompt'], row['question']]) + \" [SEP] \"\n","\n","  for choice in row['choices']:\n","        # text = item['sent1'] + \" \" + item['sent2'] + \" \" + item[f'ending{i}']\n","        choices.append([prompt, choice])\n","  return choices"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["50a00f04fc154dd1a9ca920b675acea5","0b6eb438de7a426595131a2aeedc1d18","63e5f678f0d34887940d7ce871c9b7a3","b01777e3e5c34e6aa8e12c189b5202ef","614d1f8c36ab498bb94368310ad3f1f5","14811500b56b46eda7f8ab662fad3e7c","fd9dcf98a54f4384b247cf2f57ab0b5a","e9795b7c169c4bedb5e2003ccac6eb3c","bdd84d3bbe8c40d1827c5d0cbcf73954","6096dd2cbbae4854a41ef88b15809df4","21ca0ddb6c0949f48281f1dfa4eda0ec","07967863bc8542a6b0fe57b168b4b31d","1ba9882b55c74cc785a0f9c670330dfc","401171b185d0435a8e7e4c008ab29171","2354b1b2d1c04a0cbbb8d4bf6fe324f2","69e2ff488526495aa82cdde04c9b2f2d","a143d89b80ae4656bfc2c570bd614658","9eac01ed7a77452a858b63f3c3c012e6","4744482757484e8f8544e593f16aa993","fdf28f5932c5441996f9c08a84b240a8","e29e17b6d071475b9105a2d7958b3672","64a4764f3a624f4b96267d4520375387","91ff851129ff4547a4ed16d13ca3c671","3cdf56458108450096dabbdc6a83278f","3fe6a66a564c4afaa7a6736b29f688f7","4d8ee3c53ef24b4b8de91146dcddd186","3337ef5616a6457d92ed98582454eb86","947ee747c73744e38ce74ab35c31a11b","117cc3422f724aa6ba33e67718dedaa7","c4559b0b7e584c01bce66b883fb5b966","401af5ead30847f1bf73abeca3fd9d90","f5e1a616200b46289e54fb1edf5deea9","bb709a2a9e03498bbd2ba2f08a9affdc","ed053e8f47194e7eb9eeb9ba5d4b34f6","3a2b4d9351a3482d9f650f931c131b02","9699d3a918ba452fac5530a3ea4633b1","7debeb1365df4c1fb55ad331f343faa0","f2158023b93046f5849efb9b45158f0d","2619f76d3f5a4d9dbf81173dffdf78d7","b61ba3b2ad0d4c3c8e22d0f25722767e","e2d19d69e4a842029539f4ba29515c73","bc8b21890c714fc19753fad9349be069","17933742059a4255aeea06940a59dde4","b2df8333e560427fbbc566f75251111a"]},"executionInfo":{"elapsed":5121,"status":"ok","timestamp":1683056463104,"user":{"displayName":"Evan Powell","userId":"11390524329421785152"},"user_tz":240},"id":"A4GLS6sepG0y","outputId":"5ccc1bac-c9a2-4274-c87e-62c09eaedd98"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"50a00f04fc154dd1a9ca920b675acea5","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"07967863bc8542a6b0fe57b168b4b31d","version_major":2,"version_minor":0},"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"91ff851129ff4547a4ed16d13ca3c671","version_major":2,"version_minor":0},"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ed053e8f47194e7eb9eeb9ba5d4b34f6","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["#load the distilbert tokenizer and the fine-tuned model\n","mc_tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n","mc_model = AutoModelForMultipleChoice.from_pretrained(r\"/content/drive/MyDrive/CS542/mcfor\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MHbz1L9swBIM"},"outputs":[],"source":["def mc_predict(test_questions):\n","  \"\"\"given the test questions, make predictions on the multiple choice question in the set.\n","  This function will return a dictionary, where the keys are question ids and the values are \n","  predictions\"\"\"\n","\n","  df_test = pd.DataFrame(test_questions)\n","  mc_test = df_test.loc[df_test['qtype'] == 'mc']\n","  mc_test_data = mc_preptest(mc_test)\n","\n","  predictions = {}\n","  probabilities = {}\n","\n","  for i in range(len(mc_test_data)):\n","    this_question = mc_preprocess_candidates(mc_test_data.iloc[i])\n","\n","    inputs = mc_tokenizer(this_question, return_tensors=\"pt\", padding=True)\n","    labels = torch.tensor(0).unsqueeze(0)\n","\n","    outputs = mc_model(**{k: v.unsqueeze(0) for k, v in inputs.items()}, labels = labels)\n","    logits = outputs.logits\n","\n","    probs = F.softmax(logits, dim=-1).squeeze().tolist()\n","    predicted_class = logits.argmax().item()\n","\n","    question_id = mc_test_data.iloc[i][\"id\"]\n","\n","    if question_id in predictions:\n","      while question_id in predictions and len(question_id) < 11:\n","        question_id += \"a\"\n","\n","    predictions[question_id] = predicted_class\n","    probabilities[question_id] = probs\n","\n","  return probabilities\n"]},{"cell_type":"markdown","metadata":{"id":"8lldXpOlqUNe"},"source":["## True / False Forecaster"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1lNSLOqdpYt8"},"outputs":[],"source":["def prepare_truef_set(test_truef):\n","  \"\"\" prepares a dataframe test_truef for the true / false forecaster \"\"\"\n","  test_truef['len background'] = test_truef['background'].str.len()\n","  test_truef['len question'] = test_truef['question'].str.len()\n","\n","  test_truef['total prompt'] = test_truef['question'] + ' ' + test_truef['background']\n","\n","  test_truef['len prompt'] = test_truef['total prompt'].str.len()\n","\n","  test_truef['total prompt'] = test_truef.apply(lambda x : x['total prompt'][0:511] if x['len prompt'] > 512 else x['total prompt'], axis = 1)\n","\n","  test_truef['total prompt'].str.len().max\n","\n","  return test_truef"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZEqGcFhxrHCO"},"outputs":[],"source":["#load the distilbert-base-uncased tokenizer\n","truef_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wYyqhLiUrMHM"},"outputs":[],"source":["# load the fine-tuned model\n","checkpoint_dir = \"/content/drive/MyDrive/CS542/tf_checkpoints\"\n","truef_model = AutoModelForSequenceClassification.from_pretrained(checkpoint_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c7qu9XVYrej0"},"outputs":[],"source":["class GoodJudgementDatasetTest(torch.utils.data.Dataset): \n","  #Class for the true / false subset\n","    def __init__(self, encodings, labels, ids, split=\"test\", val_split=0.1):\n","        self.encodings = encodings\n","        self.labels = labels\n","        self.ids = ids\n","        self.split = split\n","        self.val_split = val_split #only needed for training the model\n","        self.indices = self.generate_indices()\n","\n","    def __getitem__(self, idx):\n","        index = self.indices[idx]\n","        item = {key: torch.tensor(val[index]) for key, val in self.encodings.items()}\n","        item[\"id\"] = self.ids[idx]\n","        if self.labels is not None:\n","          item['labels'] = torch.tensor(self.labels[index])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.indices)\n","\n","    def get_labels(self):\n","        return [self.labels[i] for i in self.indices]\n","\n","    def generate_indices(self):\n","      if self.split == \"test\":\n","        return np.arange(len(self.encodings['input_ids']))\n","      else:\n","        indices = np.arange(len(self.labels))\n","        np.random.shuffle(indices)\n","        split_idx = int(self.val_split * len(indices))\n","\n","        if self.split == \"train\":\n","            return indices[split_idx:]\n","        elif self.split == \"val\":\n","            return indices[:split_idx]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VnkqwNgryPCQ"},"outputs":[],"source":["def truef_predict(test_questions):\n","  \"\"\"given the test questions, make predictions on the true / false questions in the set.\n","  This function will return a dictionary, where the keys are the question ids and the values\n","  are the prediction values\"\"\"\n","\n","  test_df = pd.DataFrame(test_questions)\n","  test_truef = test_df.loc[test_df['qtype'] == 't/f']\n","\n","  \n","\n","  test_truef = prepare_truef_set(test_truef)\n","\n","  test_ids_truef = test_truef['id'].tolist()\n","  test_sentences_truef = test_truef['total prompt'].values.tolist()\n","  test_encodings_truef = truef_tokenizer(test_sentences_truef, truncation=True, padding=True, return_tensors='pt')\n","\n","  test_dataset_truef = GoodJudgementDatasetTest(test_encodings_truef, None, test_ids_truef, split=\"test\")\n","\n","  truef_model.eval()\n","\n","  predictions = {}\n","  probabilities_dict = {}\n","\n","  for i in range(len(test_dataset_truef)):\n","    input_ids = test_dataset_truef[i]['input_ids'].unsqueeze(0)\n","    attention_mask = test_dataset_truef[i]['attention_mask'].unsqueeze(0)\n","    inputs = {'input_ids': input_ids, 'attention_mask': attention_mask}\n","\n","    if 'token_type_ids' in test_dataset_truef[i]:\n","      token_type_ids = test_dataset_truef[i]['token_type_ids'].unsqueeze(0)\n","      inputs['token_type_ids'] = token_type_ids\n","\n","    # Make a prediction\n","    with torch.no_grad():\n","      outputs = truef_model(**inputs)\n","\n","    # Process the output to obtain the prediction\n","    logits = outputs.logits\n","    probabilities = torch.softmax(logits, dim=-1)\n","    predicted_class = torch.argmax(probabilities, dim=-1).item()\n","\n","    question_id = test_dataset_truef[i][\"id\"]\n","\n","    if question_id in predictions:\n","      while question_id in predictions and len(question_id) < 11:\n","        question_id += \"a\"\n","\n","    predictions[ question_id ] =  predicted_class\n","    probabilities_dict[question_id] = softmax(logits.cpu().numpy(), axis=-1).tolist()[0]\n","\n","  return probabilities_dict"]},{"cell_type":"markdown","metadata":{"id":"eE5R2feIsDPO"},"source":["## Numeric Forecaster"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XqLs2YHBsBOg"},"outputs":[],"source":["num_model_path = \"/content/drive/MyDrive/CS542/numforecast\" \n","num_model = DistilBertForSequenceClassification.from_pretrained(num_model_path)\n","num_tokenizer = tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OiXPxihp7sFL"},"outputs":[],"source":["def num_preptesting(mc):\n","    \"\"\"modified form of preptrainig - commented out the lines that cannot be done to the test set\"\"\"    \n","\n","    mc['prompt'] = mc['dtype'].apply(lambda x: \"The data given is in the units: \" + str(x) + \" [SEP] \" if x is not None else \"The data is given only from zero to one [SEP] \")\n","\n","    return mc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Smc7XlY570Jf"},"outputs":[],"source":["class NumTestDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, ids):\n","        self.encodings = encodings\n","        self.ids = ids\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['id'] = self.ids[idx]\n","        return item\n","\n","    def __len__(self):\n","        return len(self.encodings[\"input_ids\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"soHvaGkm72d4"},"outputs":[],"source":["def predict_single_datapoint(model, input_text, tokenizer):\n","    # Put the model in evaluation mode\n","    model.eval()\n","\n","    # Tokenize the input text using the provided tokenizer\n","    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True, padding=\"max_length\")\n","\n","    # Move the input tensors to the device (either GPU or CPU)\n","    input_ids = inputs[\"input_ids\"] #.to(device)\n","    attention_mask = inputs[\"attention_mask\"] #.to(device)\n","\n","    with torch.no_grad():\n","        # Forward pass through the model to get the logits\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","\n","        # Get the predicted logits\n","        logits = outputs.logits\n","\n","        # Detach and move the logits to the CPU\n","        logits = logits.detach().cpu().numpy()\n","\n","    # Return the regression value\n","    return logits[0][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"peRY4v_x8Llr"},"outputs":[],"source":["def num_predict(test_questions):\n","  \"\"\"given the test questions, make predictions on the numeric questions in the set.\n","  This function will return a dictionary, where the keys are the question ids and the values\n","  are the prediction values\"\"\"\n","  df_test = pd.DataFrame(test_questions)\n","  num_test = df_test.loc[df_test['qtype'] == 'num']\n","\n","  num_test['dtype'] = num_test['choices'].apply(lambda x: type(x['max']) if x is not None else None)\n","\n","  num_test_data = num_preptesting(num_test)\n","  num_test_dataholder = num_test_data[['id', 'prompt']]\n","\n","  num_test_encodings = tokenizer(num_test_dataholder['prompt'].tolist(), truncation=True, padding=True)\n","\n","  num_test_dataset = NumTestDataset(num_test_encodings, num_test_dataholder['id'].tolist())\n","  num_test_dataloader = DataLoader(num_test_dataset, batch_size=1)\n","\n","  predictions = {}\n","\n","  for batch in num_test_dataloader:\n","    input_ids = batch['input_ids']\n","    attention_mask = batch['attention_mask']\n","    data_id = batch['id'][0]\n","    input_text = tokenizer.decode(input_ids.squeeze())\n","    prediction = predict_single_datapoint(num_model, input_text, num_tokenizer)\n","    predictions[data_id] = prediction\n","\n","  return predictions"]},{"cell_type":"markdown","metadata":{"id":"MNyf3owlnUcl"},"source":["# Evaluate the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lR4b6mDInUcm","outputId":"4fda6c6c-39eb-4645-97c0-babc5b8ad2a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["T/F: 25.00, MCQ: 38.05, NUM: 22.63\n","Combined Metric: 85.67\n"]}],"source":["tf_results, mc_results, num_results = [],[],[]\n","for p, a, qtype in zip(preds, answers, qtypes):\n","    if qtype == 't/f':\n","        tf_results.append(brier_score(p, a))\n","    elif qtype == 'mc':\n","        mc_results.append(brier_score(p, a))\n","    else:\n","        num_results.append(np.abs(p - a))\n","\n","print(f\"T/F: {np.mean(tf_results)*100:.2f}, MCQ: {np.mean(mc_results)*100:.2f}, NUM: {np.mean(num_results)*100:.2f}\")\n","print(f\"Combined Metric: {(np.mean(tf_results) + np.mean(mc_results) + np.mean(num_results))*100:.2f}\")"]},{"cell_type":"markdown","metadata":{"id":"NtYdp4crnUco"},"source":["# Make predictions on test set"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FcJP3ZElnUcp"},"outputs":[],"source":["old_preds = []\n","for question in test_questions:\n","    old_preds.append(calibrated_random_baseline_model(question))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":191,"status":"ok","timestamp":1683059748132,"user":{"displayName":"Evan Powell","userId":"11390524329421785152"},"user_tz":240},"id":"juRqGqIiLZf9","outputId":"43bf6602-bbfe-4ab8-a1fb-52be56104da0"},"outputs":[{"data":{"text/plain":["1364"]},"execution_count":99,"metadata":{},"output_type":"execute_result"}],"source":["len(old_preds)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J3ovPKyE9e96"},"outputs":[],"source":["preds = []\n","id_list = list(map(str, [question['id'] for question in test_questions]))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":256847,"status":"ok","timestamp":1683061576312,"user":{"displayName":"Evan Powell","userId":"11390524329421785152"},"user_tz":240},"id":"Fwsctglx-Th6","outputId":"e8d76c98-9eb4-4e49-b010-5221f49c854b"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-22-63a2175f3ea6>:3: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  test_truef['len background'] = test_truef['background'].str.len()\n","<ipython-input-22-63a2175f3ea6>:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  test_truef['len question'] = test_truef['question'].str.len()\n","<ipython-input-22-63a2175f3ea6>:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  test_truef['total prompt'] = test_truef['question'] + ' ' + test_truef['background']\n","<ipython-input-22-63a2175f3ea6>:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  test_truef['len prompt'] = test_truef['total prompt'].str.len()\n","<ipython-input-22-63a2175f3ea6>:10: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  test_truef['total prompt'] = test_truef.apply(lambda x : x['total prompt'][0:511] if x['len prompt'] > 512 else x['total prompt'], axis = 1)\n","<ipython-input-25-ebf87e4e73ab>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item = {key: torch.tensor(val[index]) for key, val in self.encodings.items()}\n"]}],"source":["truef_preds = truef_predict(test_questions)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":153677,"status":"ok","timestamp":1683061784309,"user":{"displayName":"Evan Powell","userId":"11390524329421785152"},"user_tz":240},"id":"aAX12P4W_itb","outputId":"217f4854-a1a0-432b-e883-f84391008d9d"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-17-ae4045ed9b52>:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  mc_test['len background'] = mc_test['background'].str.len()\n","<ipython-input-17-ae4045ed9b52>:5: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  mc_test['len question'] = mc_test['question'].str.len()\n","<ipython-input-17-ae4045ed9b52>:6: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  mc_test['len answers'] = mc_test['choices'].apply(lambda x : [len(ans) for ans in x])\n","<ipython-input-17-ae4045ed9b52>:7: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  mc_test['len answers'] = mc_test['len answers'].apply(lambda x: max(x))\n","<ipython-input-17-ae4045ed9b52>:9: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  mc_test['temp'] = mc_test['len background'] - x*2 - mc_test['len answers'] - mc_test['len question']\n","<ipython-input-17-ae4045ed9b52>:10: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  mc_test['max context length'] = ((-1 * (mc_test['len answers'] + mc_test['len question']) + x*2) + 512)\n","<ipython-input-17-ae4045ed9b52>:13: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  mc_test['max context length'] = test.apply(lambda row: row.min(), axis=1)\n","<ipython-input-17-ae4045ed9b52>:14: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  mc_test['prompt'] = mc_test.apply(lambda x: x['background'][:x['max context length']], axis=1)\n","<ipython-input-17-ae4045ed9b52>:15: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  mc_test['len prompt'] = mc_test['prompt'].str.len()\n"]}],"source":["mc_preds = mc_predict(test_questions)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":351761,"status":"ok","timestamp":1683057945044,"user":{"displayName":"Evan Powell","userId":"11390524329421785152"},"user_tz":240},"id":"dck-gZJK_ju2","outputId":"71e15810-3a0e-406b-b438-2068f98852ef"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-53-65baf36a7c51>:8: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  num_test['dtype'] = num_test['choices'].apply(lambda x: type(x['max']) if x is not None else None)\n","<ipython-input-28-5197705ffb65>:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  mc['prompt'] = mc['dtype'].apply(lambda x: \"The data given is in the units: \" + str(x) + \" [SEP] \" if x is not None else \"The data is given only from zero to one [SEP] \")\n"]}],"source":["num_preds = num_predict(test_questions)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XHjq1Tb--UL2"},"outputs":[],"source":["merged_preds = {}\n","merged_preds.update(truef_preds)\n","merged_preds.update(mc_preds)\n","merged_preds.update(num_preds)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":167,"status":"ok","timestamp":1683061837470,"user":{"displayName":"Evan Powell","userId":"11390524329421785152"},"user_tz":240},"id":"Xu4OrorbExRu","outputId":"3670ef32-4a92-4cf9-8b50-ff56f2b22b13"},"outputs":[{"name":"stdout","output_type":"stream","text":["1364\n","826\n","182\n","356\n","1364\n"]}],"source":["print(len(test_questions))\n","print(len(truef_preds))\n","print(len(mc_preds))\n","print(len(num_preds))\n","print(len(merged_preds))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eTVi-qjw-pv2"},"outputs":[],"source":["preds = []\n","for i in range(len(id_list)):\n","  this_id = id_list[i]\n","  if this_id in id_list[:i]:\n","    while this_id in id_list[:i] and len(this_id) < 11: #there are multiple questions that share the same id\n","      this_id += \"a\"\n","\n","  if this_id not in merged_preds:\n","    print(\"Not in merged_preds, id: \" + this_id)\n","  else:\n","    preds += [merged_preds[this_id]]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":170,"status":"ok","timestamp":1683061846015,"user":{"displayName":"Evan Powell","userId":"11390524329421785152"},"user_tz":240},"id":"UaTic0J-LOty","outputId":"ce21921f-7363-4832-821a-ef6fed9805c6"},"outputs":[{"data":{"text/plain":["1364"]},"execution_count":125,"metadata":{},"output_type":"execute_result"}],"source":["len(preds)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":195,"status":"ok","timestamp":1683062150141,"user":{"displayName":"Evan Powell","userId":"11390524329421785152"},"user_tz":240},"id":"qiBf9mFknUcq","outputId":"5c699078-6a3e-4597-dd47-413df03b0a56"},"outputs":[{"name":"stdout","output_type":"stream","text":["updating: predictions.pkl (deflated 63%)\n"]}],"source":["if not os.path.exists('submission'):\n","    os.makedirs('submission')\n","\n","with open(os.path.join('submission', 'predictions.pkl'), 'wb') as f:\n","    pickle.dump(preds, f, protocol=2)\n","\n","!cd submission && zip ../submission.zip ./* && cd .."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":249,"status":"ok","timestamp":1683061855133,"user":{"displayName":"Evan Powell","userId":"11390524329421785152"},"user_tz":240},"id":"yOwwi3OInUcs","outputId":"92ff8229-b427-4a7d-8cdc-e7eae90aad20"},"outputs":[{"name":"stdout","output_type":"stream","text":["drive  sample_data  submission\tsubmission.zip\n"]}],"source":["!dir"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zHk8PIk_nUcs"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":["TGyXl-5ToVzY","Z8z8tvnRqLe4","lPVSvVJWon3m","eE5R2feIsDPO","MNyf3owlnUcl"],"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"vscode":{"interpreter":{"hash":"90e47ca3de7a6ac5652c507781a9a883127089d6067d2cae315ebae4b66e7ceb"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"07967863bc8542a6b0fe57b168b4b31d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1ba9882b55c74cc785a0f9c670330dfc","IPY_MODEL_401171b185d0435a8e7e4c008ab29171","IPY_MODEL_2354b1b2d1c04a0cbbb8d4bf6fe324f2"],"layout":"IPY_MODEL_69e2ff488526495aa82cdde04c9b2f2d"}},"0b6eb438de7a426595131a2aeedc1d18":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_14811500b56b46eda7f8ab662fad3e7c","placeholder":"​","style":"IPY_MODEL_fd9dcf98a54f4384b247cf2f57ab0b5a","value":"Downloading (…)okenizer_config.json: 100%"}},"117cc3422f724aa6ba33e67718dedaa7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"14811500b56b46eda7f8ab662fad3e7c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17933742059a4255aeea06940a59dde4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ba9882b55c74cc785a0f9c670330dfc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a143d89b80ae4656bfc2c570bd614658","placeholder":"​","style":"IPY_MODEL_9eac01ed7a77452a858b63f3c3c012e6","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"21ca0ddb6c0949f48281f1dfa4eda0ec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2354b1b2d1c04a0cbbb8d4bf6fe324f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e29e17b6d071475b9105a2d7958b3672","placeholder":"​","style":"IPY_MODEL_64a4764f3a624f4b96267d4520375387","value":" 232k/232k [00:00&lt;00:00, 2.58MB/s]"}},"2619f76d3f5a4d9dbf81173dffdf78d7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3337ef5616a6457d92ed98582454eb86":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a2b4d9351a3482d9f650f931c131b02":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2619f76d3f5a4d9dbf81173dffdf78d7","placeholder":"​","style":"IPY_MODEL_b61ba3b2ad0d4c3c8e22d0f25722767e","value":"Downloading (…)lve/main/config.json: 100%"}},"3cdf56458108450096dabbdc6a83278f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_947ee747c73744e38ce74ab35c31a11b","placeholder":"​","style":"IPY_MODEL_117cc3422f724aa6ba33e67718dedaa7","value":"Downloading (…)/main/tokenizer.json: 100%"}},"3fe6a66a564c4afaa7a6736b29f688f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4559b0b7e584c01bce66b883fb5b966","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_401af5ead30847f1bf73abeca3fd9d90","value":466062}},"401171b185d0435a8e7e4c008ab29171":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4744482757484e8f8544e593f16aa993","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fdf28f5932c5441996f9c08a84b240a8","value":231508}},"401af5ead30847f1bf73abeca3fd9d90":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4744482757484e8f8544e593f16aa993":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d8ee3c53ef24b4b8de91146dcddd186":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5e1a616200b46289e54fb1edf5deea9","placeholder":"​","style":"IPY_MODEL_bb709a2a9e03498bbd2ba2f08a9affdc","value":" 466k/466k [00:00&lt;00:00, 12.7MB/s]"}},"50a00f04fc154dd1a9ca920b675acea5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0b6eb438de7a426595131a2aeedc1d18","IPY_MODEL_63e5f678f0d34887940d7ce871c9b7a3","IPY_MODEL_b01777e3e5c34e6aa8e12c189b5202ef"],"layout":"IPY_MODEL_614d1f8c36ab498bb94368310ad3f1f5"}},"6096dd2cbbae4854a41ef88b15809df4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"614d1f8c36ab498bb94368310ad3f1f5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63e5f678f0d34887940d7ce871c9b7a3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9795b7c169c4bedb5e2003ccac6eb3c","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bdd84d3bbe8c40d1827c5d0cbcf73954","value":28}},"64a4764f3a624f4b96267d4520375387":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"69e2ff488526495aa82cdde04c9b2f2d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7debeb1365df4c1fb55ad331f343faa0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_17933742059a4255aeea06940a59dde4","placeholder":"​","style":"IPY_MODEL_b2df8333e560427fbbc566f75251111a","value":" 483/483 [00:00&lt;00:00, 23.0kB/s]"}},"91ff851129ff4547a4ed16d13ca3c671":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3cdf56458108450096dabbdc6a83278f","IPY_MODEL_3fe6a66a564c4afaa7a6736b29f688f7","IPY_MODEL_4d8ee3c53ef24b4b8de91146dcddd186"],"layout":"IPY_MODEL_3337ef5616a6457d92ed98582454eb86"}},"947ee747c73744e38ce74ab35c31a11b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9699d3a918ba452fac5530a3ea4633b1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2d19d69e4a842029539f4ba29515c73","max":483,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bc8b21890c714fc19753fad9349be069","value":483}},"9eac01ed7a77452a858b63f3c3c012e6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a143d89b80ae4656bfc2c570bd614658":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b01777e3e5c34e6aa8e12c189b5202ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6096dd2cbbae4854a41ef88b15809df4","placeholder":"​","style":"IPY_MODEL_21ca0ddb6c0949f48281f1dfa4eda0ec","value":" 28.0/28.0 [00:00&lt;00:00, 1.35kB/s]"}},"b2df8333e560427fbbc566f75251111a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b61ba3b2ad0d4c3c8e22d0f25722767e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb709a2a9e03498bbd2ba2f08a9affdc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bc8b21890c714fc19753fad9349be069":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bdd84d3bbe8c40d1827c5d0cbcf73954":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c4559b0b7e584c01bce66b883fb5b966":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e29e17b6d071475b9105a2d7958b3672":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2d19d69e4a842029539f4ba29515c73":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9795b7c169c4bedb5e2003ccac6eb3c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed053e8f47194e7eb9eeb9ba5d4b34f6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3a2b4d9351a3482d9f650f931c131b02","IPY_MODEL_9699d3a918ba452fac5530a3ea4633b1","IPY_MODEL_7debeb1365df4c1fb55ad331f343faa0"],"layout":"IPY_MODEL_f2158023b93046f5849efb9b45158f0d"}},"f2158023b93046f5849efb9b45158f0d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5e1a616200b46289e54fb1edf5deea9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd9dcf98a54f4384b247cf2f57ab0b5a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fdf28f5932c5441996f9c08a84b240a8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}